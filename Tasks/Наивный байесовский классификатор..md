
```dataview 	
TABLE without id	
file.outlinks AS "OUTGOING", 	
file.inlinks AS "BACKLINKS"	
WHERE file.name = this.file.name 
```

#reference

# Links

# Description
На примере **Теоремы Байеса** построена концепция **наивного байесовского классификатора** - одной из основных моделей машинного обучения.

Однако, между теоремой и классификацией есть важное отличие: условная независимость. В теореме речь идет о взаимосвязанных событиях, в классификаторе же наоборот - все объекты, события, свойства являются независимыми.
Это может не соответствовать реальности, однако такой наивный подход помогает быстрее обучать модель и упрощает расчет вероятностей.

В Google Colab в тетради по машинному обучению показано, как использовать наивный байесовский классификатор в обучении модели. Там используется датасет из библиотеки Scikit-learn цветков ириса. [[ScikitLearn. Load_Iris. Dataset]]

**С помощью алгоритма можно вычислить с какой вероятностью объект принадлежит к определенному классу цветков, при условии, что имеет его характеристики.**


```dataview 	
TABLE without id	
file.outlinks AS "OUTGOING", 	
file.inlinks AS "BACKLINKS"	
WHERE file.name = this.file.name 
```

#reference

# Links

# Description
Вероятность - это теоретическое изучение измерения в уверенности в том, что какое-либо событие произойдет. Это основополагающая дисциплина для статистики, проверки гипотез, машинного обучения и прочего.  

Будет рассмотрены математические понятия, связанные с вероятностью, теорему Байеса, биномиальное распределение и бета-распределение.
1) **Определение вероятности**: 
	Самый популярный способ выразить вероятность - в процентах. Мы будем называть ее P(X). Не стоит путать “возможность” (Likehood) и “вероятность” (Probability). “Вероятность” основывается на вещах и событиях, которые будут происходить, а “возможность” основывается на том, что уже произошло. В статистике и машинном обучении используется возможность (прошлое), а для прогнозирования используется вероятность (будущее). 
    Еще одним различием является то, что сумма вероятностей всех событий в процентах равна 100, а возможность этому правилу не подчиняется. 
    
    Вероятность можно представить в виде соотношения O(X), например, 7:3 или 7/3. Чтобы преобразовать O(X) в P(X) нужно использовать формулу: 
	    **P(X) = O(X) / (1 + O(X))**. 
    И наоборот, можно получить O(X) из P(X), если разделить вероятность наступления события на вероятность не наступления. Соотношение бывает полезным, так как более наглядно показывает какая вероятность выше. Оно используется в байесовской статистике и в логистической регрессии.
2) **Вероятность против статистики**:
	Нередко вероятность и статистику представляют как синонимы, хотя у них есть различия. Вероятность можно рассчитать без данных, так как это чисто теоретическое понятие. А статистика, наоборот, состоит только из данных, и использует эти данные для определения вероятности и предоставляет инструменты для описания данных.
3) **Математика вероятностей**:
	Когда мы работаем с предельной вероятностью P(X), то все кажется более и менее простым.
	1) **Совместные вероятности**: если мы хотим найти вероятность, когда два отдельных события произойдут одновременно, это называется совместной вероятностью. Его можно представить как логический оператор И. Вероятности нужно перемножить между собой, чтобы найти их одновременную вероятность. Мы могли бы просто рассчитать все возможные исходы и найти подходящий, но правилом произведения это можно сделать намного быстрее.
	2) **Объединенные вероятности**: вероятность наступления одного события или другого события (А ИЛИ Б). Рассчитывается путем сложения вероятностей одного события и другого. Но следует учитывать, что при сложении вероятности мы можем продублировать одну и ту же вероятность и ответ будет неверным. Поэтому, по правилу сложения вероятностей, следует также вычесть совместную вероятность (произведение).
	3) **Условная вероятность и теорема Байеса**: вероятность наступления события А при условии, что произошло событие Б. Выражается как P(A|B). В книге рассматривается случай, когда условная вероятность выражает процент людей, которые пьют кофе с онкологическим заболеванием. Нужно посчитать условную вероятность того, что из-за кофе возникает рак (то есть обратная ситуация). Для этого используется теорема Байеса: P(A|B) = (P(B|A) * P(A)) / P(B). Она определяет обратную условную вероятность (переворачивает).
		![[Pasted image 20251016232605.png]] - формула теоремы Байеса.
		Это формула использует апостериорные данные (данные, основанные на опыте или наблюдении) P(B|A). P(A) и P(B) являются априорными вероятностями, или безусловными, то есть вероятность основана на имеющихся данных до наблюдения или опыта.
		Априорная вероятность пересматривается при поступлении новых данных и становится условной (апостериорной). **Сначала есть убеждение или гипотеза, затем данные обновляются после опыта, эксперимента или наблюдения и на основе новых данных обновляют первоначальное убеждение.**
		***Суть теоремы Байеса в том, что она не строит вероятность с нуля, а уточняет уже имеющиеся данные. То есть обновляет априорную вероятность.***
		[[Парадокс Монти Холла. Пример визуализации вероятности.]] 
		В объяснении этого парадокса используется теорема Байеса.
		На основе теоремы Байеса основана модель машинного обучения - [[Наивный байесовский классификатор.]]
		
	4) **Совместные и объединенные вероятности**: 
		задача найти вероятность того, что человек пьет кофе и у него есть рак. Что мы должны использовать: P(Coffee|Cancer) или P(Coffee)? Так как мы уже установили, что рассматриваем только тех, у кого есть рак, то лучше использовать условную вероятность. 
		Если событие А не влияет на событие Б, то что это значит для условной вероятности P(B|A)? Это означает, что P(B|A) = P(B), то есть наступление события А не влияет на вероятность наступления события Б. Поэтому возникает следующая формула:  
		**P(A AND B) = P(B)\*P(A|B).** 
		Наконец, перейдем об объединениях и условной вероятности. Если нужно вычислить вероятность наступления событий А ИЛИ Б, но А может влиять на вероятность наступления Б, то: 
		**P(A OR B) = P(A) + P(B) - P(A|B)\*P(B)**
4) **Биномиальное распределение**:
	Вероятности при таком законе распределения представляют собой слагаемые в разложении бинома Ньютона. 
	Пример: рассматривается работа турбинного двигателя, и мы провели 10 тестов. Результат показал 8 успешных и 2 провальных испытания. Это значит, что с текущими данными вероятность успеха равна всего лишь 80%. Но если провести больше испытаний, результат может измениться. 
	Здесь поможет биномиальное распределение, которое показывает, насколько вероятно наступление k успехов в n испытаниях при заданной вероятности p. 
	Реализовать биномиальное распределение с нуля можно применяя формулу для расчета биномиального распределения:
	![[Pasted image 20250815223751.png]]
	![[Pasted image 20251015134729.png]]
		**Если в каждом из n независимых опытов некое событие А может появиться с вероятностью p и не появиться с вероятностью 1-p, то вероятность появления события А в этих n опытах ровно m раз определяется по формуле.**
	Число сочетаний (из n по k) - число способов, сколькими способами из n различных элементов можно выбрать k штук без учета порядка.
5) **Бета распределение**:
	Проблематичным в биномиальном распределении является то, что за базовый показатель успешности мы берем одно значение. Что если помимо него существуют и другие показатели, которые бы обеспечили такую же вероятность успеха. Вместо того, чтобы создавать бесчисленное множество биномиальных распределений для ответа на этот вопрос, можно воспользоваться одним инструментом. Бета распределение позволяет нам увидеть вероятность различных базовых вероятностей наступления события при условии альфа-успехов и бета-неудач. 
	**В Байесовском анализе бета-распределение используется для предварительного распределения параметра p (который ограничен между 1 и 0) для биномиального распределения.**
	Ось Х представляет все возможные вероятности успеха от 0 до 1 (от 1% до 100%), а ось Y представляет вероятность этой вероятности при восьми успехах (альфа) и двух неудачах (бета). 
	Бета-распределение является непрерывной функцией, заданное значение плотности на оси Y не является вероятностью. Вместо этого находим вероятности, используя площади под кривой. Площадь под всей кривой равна 1. 
	Чтобы найти вероятность, нужно найти площадь в пределах диапазона. Например, если хотим оценить вероятность того, что 8 из 10 успехов приведут к 90%, нужно найти площадь между 0.9 и 1.0, которая равна 0.225. 
	Каждое непрерывное распределение вероятностей имеет функцию кумулятивной плотности (CDF), которая вычисляет площадь до заданного значения х. 
	**Функция кумулятивной плотности** - это функция, которая показывает вероятность того, что случайная величина Х примет значение меньше или равное х. 
	С помощью библиотеки SciPy можно вычислять бета-распределение.

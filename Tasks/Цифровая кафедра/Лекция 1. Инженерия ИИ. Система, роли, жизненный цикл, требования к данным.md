
```dataview 	
TABLE without id	
file.outlinks AS "OUTGOING", 	
file.inlinks AS "BACKLINKS"	
WHERE file.name = this.file.name 
```

#reference #машинноеобучение #программирование #аналитикаданных #цифроваякафедра #лекция

# Links

# Description
## Рамка курса

---

**Результатом окончания курса является готовый репозиторий с кодом, моделью, API-сервисом, наблюдаемостью и безопасностью.**

---
## Что получим на выходе
1) Репозиторий кода: личный репозиторий с кодом проекта, включая структуру, модули, тесты и понятный README
2) Модели и эксперименты: обученные модели и протокол экспериментов, показывающие, какие варианты пробовали и какие метрики получили. Будем уметь объяснять, почему была выбрана та или иная модель, путь к этому решению. Протокол экспериментов будем хранить на MLFlow специализированный для проведения экспериментов, либо в таблицах.
3) API-сервис: по запросу дает предсказания (эндпоинт) и health-check для проверки.
4) Контейнеризация Docker: все будет завернуто в Docker образ, который можно будет поднять одной командой. .
5) Минимальный мониторинг: Вокруг сервиса появятся базовые объекты наблюдаемости: логи запросов, несколько метрик по количеству вызовов, по времени ответа, по качеству предсказаний, а также простые отчеты.
6) Документация по безопасности и работе с данными: включает SECURITY.md, правила логирования и обращения с секретами.
7) Понимание роли ИИ: понимание роли ИИ-компонента в системе и умение объяснить свой проект технической и нетехнической аудитории. Например, менеджеру о том, какую задачу решает ИИ-система, какие метрики для нее важны, где она может ошибаться и главное как это отслеживается.
## ИИ-модели
В первую очередь нужно **описать постановку задачи с точки зрения математики и программирования**. Каким образом перенести бизнес задачу в эти понятия.
Не существует четкого ответа на вопрос: а какую модель использовать. Нужно проверить несколько вариантов моделей и провести серию экспериментов, которые показывали бы какая модель лучше подходит и как ее лучше настроить.
## ИИ-система состоит из взаимосвязанных компонентов
![[Pasted image 20251119215033.png]]
Эта схема содержит ключевые компоненты ии-системы.
1) **Пользователь или внешняя система** посылают запросы через **интерфейс** (веб, мобильное приложение, человек в интерфейсе, бекэнд сайта, партнерский сервис).
2) **Интерфейс и API-шлюз** принимают запрос, проверяют формат и права, передают в сервис, авторизация.
3) **Сервис с моделью** обрабатывает вход и делает предсказание.
4) **Хранилище данных** обеспечивает доступ к сырым и агрегированным данным.
5) **Хранилище моделей** хранит версии обученных моделей и позволяет выбирать нужную.
6) **Мониторинг и логи** фиксируют запросы, ответы, ошибки
7) **Конфиги и секреты** управляют настройками и доступом.
***Модель - это только один прямоугольник на диаграмме.***
Данные приходят из разных источников - пользовательский ввод, логи, базы, внешние интеграции. Все они попадают в какое то хранилище и пайплайн подготовки данных очищается, валидируется, превращается в удобный формат для моделей. Затем используются обучающие пайплайны, чтобы обновлять модель. Складываются артефакты в хранилище моделей.
С другой стороны работает сервис, который запускает модели, загружает нужную версию, отвечает на запросы в режиме онлайн.
На это все навешен мониторинг, который собирает информацию о том сколько запросов проходит, какие задержки, какие ответы выдает модель, как меняется распределение входов.
Это все позволяет поддерживать ИИ-систему в живом состоянии и замечать заранее ошибки.

В крупных компаниях большинство шагов автоматизировано, дабы избежать ошибок.

Мы должны понимать, на каком месте схемы мы сейчас находимся и какие артефакты должны появится.

## Модель и ИИ-система это разное
Определение модели - алгоритм предсказания на основе входных данных
Определение ИИ-системы - совокупность сервисов, данных, конфигураций, процессов и людей вокруг модели
Замена модели - Возможность замены модели без нарушения контракта с пользователями
Влияние системы на модель - система задает требования к модели (скорость, ресурсы).
Взаимосвязь модели и системы - от модели зависит качество ии-системы
Важность системы - важность рассмотрения системы вместе с моделью

**Какая у нас модель? (метрики) Какая у нас система и как она мешает или помогает модели?**

## Архитектура ИИ-системы
![[Pasted image 20251125111245.png]]
1) Источники данных: логи, бизнес-БД (с заказами), внешние API (открытые датасеты, сторонние сервисы). У них разный формат. Чтобы привести к общему виду, то есть скрипты которые проверяют данные и складывают в хранилище. Где они живут очень долго.
   ![[Pasted image 20251125111359.png]]
2) Ingestion-скрипты забирают данные и складывают их в DataLake (сырые данные) или DWH (data warehouse. Структурированные данные).
   ![[Pasted image 20251125111619.png]]
3) Feature Store хранит подготовленные признаки (агрегаты, статистики по товарам, текстовые признаки), которые переиспользуются в обучении и инференсе. Один раз посчитали и переиспользуем. 
4) Блок обучения моделей: эксперименты, training pipline (можно запустить повторно и получить ту же модель) и реестр моделей (каждая версия хранится со своими параметрами и можно выбрать какую модель использовать).
   ![[Pasted image 20251125111825.png]]
5) Блок инференса (запуска): API-сервис (принимает запросы), который использует выбранную версию модели из реестра.
   ![[Pasted image 20251125112018.png]]
6) Блок наблюдения: логи, метрики, конфиги и секреты (хранит настройки к бд), отвечающие за контроль и безопасные настройки.
   ![[Pasted image 20251125112101.png]]
## Пример ИИ-системы: Онлайн-магазин

1) Данные поступают в хранилище: логи и данные о заказах поступают в хранилище
2) Строятся признаки: частота покупок, категории интереса, средний чек
3) Модель предсказывает: например, какие товары рекомендовать
4) Сервис встраивается в страницу: при запросе API, модель, список товаров
5) Мониторинг отслеживает: клики по рекомендациям, конверсии и ошибки
6) Система дообучается и обновляется: по собранным данным

Задача команды - умные рекомендации. Каждый просмотр, каждый клик попадает в логи. Сбор данных о поведении пользователей. Они бесполезные, сырые, по которым можно собрать признаки. 
Из логов и заказов: сколько раз пользователь заходил на неделе, какие товары предпочитает, сколько раз просматривал карточку, сколько тратит в среднем. Это признаки числовые и категориальные. По этим признакам обучают модель. 
Возвращает модель список товаров с рейтингом релевантности. Модель попадает в хранилище моделей и затем в сервис.

Мониторинг фиксирует результаты моделей и работает ли система. 
**Модель - только середина цепочки.** 
## Жизненный цикл ИИ-системы. Повторяющиеся этапы
[[Жизненный цикл DS]]
![[Pasted image 20251125113540.png]]
1) Постановка задачи и метрик. Формулируем что хотим предсказывать. Например, повысить продажи - конверсия покупок, уменьшить долю спама в почтовом ящике - точность и полнота классификации. Важно договориться с бизнесом и командой. Без ясной постановки задачи все будет только в экспериментах.
2) Сбор и анализ данных. Решаем откуда будем брать данные и насколько они надежные. Пропуски, странные значения, несогласованный формат. Делать первичный анализ - графики, статистика.
3) Проектирование признаков и обучение моделей. Превращаем сырые данные в признаки. Пробуем базовые модели. Строим несколько альтернатив, настраиваем гиперпараметры. Сравнение вариантов и запись метрик.
4) Валидация и выбор решения. Проверяем модель на отложенных данных, которые она раньше не видела. Должны убедиться, что качество не только на тренировочном датасете. Посмотреть где модель ошибается. Нет ли утечек.
5) Развертывание и интеграция. Превращаем в сервис с апи, конфигами.
6) Мониторинг и улучшение. Ловим дрейф данных, реагировать на деградацию, собирать обратную связь. **Если что то поменялось, то цикл повторяется.**
## Жизненный цикл как пайплайн с артефактами
![[Pasted image 20251125124845.png]]
Каждый шаг жизненного цикла фиксируется артефактами: документами, кодом, данными, отчетами
1) **Постановка задачи** рождает документ с формулировкой проблемы и целевых метрик. Например, маркдаун файлы.
2) **Сбор и анализ данных** - версионированные датасеты и описание их качества. У каждого набора будет дата, источник, фильтры, замечания по качеству. Это не просто таблица без описания, а конкретный объект, к которому можно вернуться.
3) **Инжиниринг признаков** - код и спецификация признаков, которые можно переиспользовать. Какие признаки используются, в каком формате.
4) **Обучение и валидация** - набор моделей и протокол экспериментов с метриками. Это не одна модель, а несколько кандидатов, с записанными метриками, параметрами. 
5) **Развертывание и мониторинг** - API-контракты, конфиги сервиса, дашборды и алерты. 
Артефакт - осознанный, описанный результат, документ, датасет, модель, конфиг, отчет. Если их нет, то поднять работу через долгое время будет сложно.
## Бизнес-кейс оттока клиентов. Путь от бизнес проблемы до первой модели.
![[Pasted image 20251125130145.png]]
Онлайн сервис по подписке на цифровой контент. Больше людей отменяют подписку. Показатель оттока растет. Команда данных разбирается кто может скоро уйти, чтобы удержать клиентов. Инициатива всегда формулируется на языке бизнеса - растет отток, падает выручка. Задача инженера - перевести это в нормальную формулировку мл-задачи.

Команда с аналитиками **уточняют постановку задачи** - хотим предсказывать вероятность того, что конкретный клиент отменит подписку. Бинарная классификация - уйдет или не уйдет. 
Выбирается метрика качества - полнота для класса "уйдет" и тд.
Команда собирает данные - сколько времени проводит клиент, сколько раз обращался в поддержку. На основе данных строятся признаки - длительность подписки, сумма платежей.
Только потом инженеры обучают простейшую модель (логистическая регрессия).

## Роли в команде ИИ-системы
1) DataScientist - формулирует ML-задачи, исследуют данные, выбирает метрики, строит первые модели и сравнивает модели. Смотрит на распределения, ищет закономерности, пробует алгоритмы, помогает ответить на вопрос : можно ли решить эту задачу с помощью машинному обучению. Близко к математике и экспериментам. 
2) ML Engineer - превращает прототипы моделей в надежный код, интегрирует их в сервисы, отвечает за производительность и качество. Он отвечает за то чтобы модель правильно загружалась, обрабатывала правильные запросы, укладывалась во временные ограничения. 
3) Data Engineer - строит конвейеры данных, обеспечивает их качество, доступность, масштабируемость и удобные интерфейсы для ML. Отвечает за то чтобы данные появились и в нужном виде, чтобы различные ETL-процессы забирали их из источников, очищали, агрегировали в удобные хранилища.
4) MLOps Engineer - автоматизирует обучение и развертывание моделей, настраивает мониторинг, CI/CD и инфраструктуру. Следит за тем, чтобы модель можно переобучать по расписанию.
5) Product Manager/ Аналитик - Связывает бизнес-цели и ML-формулировки, помогает приоритизировать (ранжировать задачи и требования к проекту по тому, насколько они важны для достижения целей) задачи и интерпретировать результаты.
6) Доменный эксперт - приносит знание предметной области (медицины, финансов), проверяет адекватность постановок, признаков и интерпретаций модели.
![[Pasted image 20251125210104.png]]
## Роли в ИИ-проекте решают одну задачу через совместный сценарий
![[Pasted image 20251125210416.png]]
1) Product Manager - наблюдает в метриках продукта что растет отток платящих клиентов. Нужно понять кого можно попытаться удержать. Определяет бюджет, сроки и ограничения.
2) Data scientist - вместе с менеджером формулируют ML-задачу. А вместе с доменным экспертом смотрит на доступные данные, какие события децствительно значимы (увеличение числа посщений, смена тарифа). Выбирают метрики качества.
3) Data Engineer - контролирует, чтобы данные правильно и стабильно поступали в хранилище. Делает базовую структуру данных.
4) Data scientist - строит прототип модели и когда модель более менее хорошая, то подключается ML-engineer.
5) Он берет модель и упаковывает в сервис, проектирует API, добавляет валидацию формата, обработку входных данных, тесты. 
6) MLOps Engineer - настраивает pipeline переобучения, развертывание и мониторинг качества в проде.
7) В результате кейс превратится в совместную работу нескольких людей.
## Качество, объем и актуальность данных ограничивают возможности модели
![[Pasted image 20251125211353.png]]
Никакая даже самая модная и мощная модель не спасет ситуацию если данные плохие. Данные оцениваются по тому, насколько они хорошо отражают реальность, с которой работает система. 
1) грубые ошибки в полях (отрицательный возраст, дубликаты, странные выбросы). Это прямые ограничения для модели. Любой серьезный проект начинается с вопроса: а что у нас в данных. 
2) Объем и покрытие и репрезентативность: гораздо важнее насколько хорошо эти данные покрывают разные типы ситуаций, граничных случаев, редких классов. Если много примеров нормального поведения, то модель будет игнорировать редкие, но важные случаи. Репрезентативность - распределение данных на обучении похожи на распределение в реальных ситуациях.
3) Актуальность - насколько наши данные похожи на текущую реальность. Пользователи начинают вести себя иначе, данные становятся менее полезными. Это называется дрейф данных.
4) Качество разметки - доверие к целевым меткам. Правильно, например, помечен ли спам. Надежные, целевые метки, без систематических ошибок.
## Плохой кейс с логами
![[Pasted image 20251126111756.png]]
Пусть есть небольшой веб-сервис с авторизацией, личным кабинетом. Разработчики логируют буквально все, чтобы лучше понимать поведение пользователей (полные запросы, токены, e-mail, параметры формы, идентификаторы).
Логи хранятся на сервере, попадают в тестовые среды, резервные копии и ноутбуки. Это становится **хранилищем с чувствительными данными**.
Один из сотрудников решает проанализировать эти логи на своем ноутбуке. Перегружает на общий облачный диск, чтобы легче было взаимодействовать с другими сотрудниками. Но это может стать причиной утечки и юридических последствий.

***Поэтому, не стоит логировать все подряд и без ограничений.***

## Модель в ноутбуке. Пример функции предсказаний
![[Pasted image 20251126113027.png]]
- В ноутбуке строится крошечная модель на игрушечных данных
- Функция predict_risk - "микро-API". На вход число, на выходе - предсказание.
- В реальном сервисе будет похожий вызов модели, обернутый в HTTP/JSON
1) Признак = число сессий за неделю
2) X - количество сессий за последнюю неделю, y - целевые метки (риск или отток).
3) Переход от ноутбука к сервису - оборачивание такой простой программы в инфраструктуру.
## Переход от ноутбука к сервису: добавление API, конфиги и логи
![[Pasted image 20251126113742.png]]
1) Ноутбук: фундаментальные ограничения, нет стабильных интерфейсов. Это просто среда для экспериментов. 
2) API: выделить функцию предсказания, с контрактом
3) Конфигурация: вместе с API понадобится вынести настройки. YAML, JSON. Также выносятся базы данных и прочие параметры.
4) Логи: нужно систематически записывать ключевые события, также не логировать личные данные.
## Подход черного ящика

Считаем, что нам неизвестно внутреннее строение тех систем и моделей которые мы изучаем. Мы обязаны уметь измерять входную и выходную информацию из этих объектов.
Не нужно использовать модели машинного обучения когда нельзя померить входные и выходные данные. 

Задача моделирования - этo неизвестность заменить на свою модель, и при некоторых условиях эта замена произошла удачно, то есть модель ведет себя так же как и изучаемый объект, то эта модель хорошая. **Вся проблема - как эту модель построить**.

> [!NOTE]
> Устройство объекта неизвестно, но измеряемо. Модель = известная замена неизвестному

Модель - вычислительная среда, принимает входные данные, обрабатывает по определенным правилам и возвращает выходные. 

**Чтобы понять, хороша ли модель, нужно сравнить выходные данные модели и изучаемого объекта.**

*Например: система распознавания лица человека. Обучаем модель, чтобы она могла распознавать лица людей также, как и мозг человека. По природе это две разные системы, но они имеют одни выходные данные.*

Для того, чтобы мы могли создавать эти обучаемые модели, процесс устроен таким образом:
1) обязаны иметь набор данных, входные (поступает на изучаемые объекты), реакция модели на поступившие входные данные. Имея набор таких данных можно подстраивать модель для того чтобы ее работа на этих ОБУЧАЕМЫХ ДАННЫХ подстраивала саму модель. 
2) Для того чтобы модель имела возможность подстройки под эти данные, у нее должны быть какие числа, которые регулируют правила по которым модель работает. Эти числа называются **параметры**. Такие модели называются **параметрическими**.

У модели ее входы и желаемые выходы заданы, а задача обучения - подобрать правильный набор параметров, чтобы модель на известные входы подает почти или точно известные выходы.
Чтобы оценить насколько отличаются выходные данные модели от тех, которые ожидаются, используют алгоритмы сравнения или **функции ошибки** или **loss-функция**, которая в численном виде показывает насколько сильно отличаются ответы модели от действительных ответов модели.

Обратить внимание, что эта ошибка считается на данных, на которых мы обучаем модель. Но наша истинная цель - заставить работать в ситуациях когда нам неизвестная конечный результат.

Слабость модели ML - желания и возможности не совпадают. Модель может показывать хорошие выходные данные на обучающей выборке, но совершенно не работать на реальных данных.

Создание модели делиться на два этапа:
1) Процесс обучения. Подбор параметров.
2) Тестирование. Проверка модели на результатах, которые ей заранее не известны.

## Обучение = оптимизация
С математической точки зрения, **обучение = задача оптимизации.**

Есть некоторая **функция** (функция ошибки, можем ее посчитать, скалярная, возвращает одно число), и тогда вся задача обучения сводится к тому, чтобы **оптимизировать эту функцию** по параметрам.

**Найти такие параметры, чтобы при известных входах выходы модели совпадали как можно точнее с известными выходами объекта.**

Возможность создания модели ML, которая реально бы решила поставленную задачу, зависит не от **нас**, а от данных, которые были собраны (или есть ли в этих данных информация, которую можно собрать, действительно ли они полностью описывают ситуацию). 

Качество моделей определяется **адекватностью данных**.

Задача модели нейронных сетей = задача аппроксимации (приближение одной функции к другой).

Главное не количество данных, а их качество, их полнота, степень покрытия разных ситуаций. 

Машинное обучение - это не математическая наука, а инженерный перебор.
Нормальная практика - брать готовую модель и изменять на ней гиперпараметры или как-то менять ее. 
## Методы оптимизации
![[Pasted image 20260121193010.png]]

**Методы подбора неизвестных параметров модели чтобы функция ошибки была как можно меньше.** 

В самом начале при подборе параметров задаются **начальные значения/условия**. Они влияют на модель. Но как неизвестно. У всех методов обучения есть процесс инициализации (с помощью случайных значений).

Не существует лучших моделей и лучших данных. Все познается в сравнении для конкретных задач.

**Гиперпараметры** - значения, которые задаются разработчиком изначально и дальше не меняются (размер модели, сколько вычислений, количество параметров, размеры обучаемых и тестовых выборок). Многие модели содержат связанные между собой элементы вычислительных, количество этих элементов тоже является **гиперпараметром**. Эти гиперпараметры тоже нужно подбирать, но методов их подбора нет, только **перебором**.

Случайность - важный элемент в методах оптимизации. 

По методу:
1) **Переборные**: Перебор возможных решений (возможные значения параметров по своему усмотрению), сравниваем между собой функции ошибки для разного набора параметров и выбрать лучший. 
   Все переборные методы страдают от **размерности**. Если кандидатов очень много, то перебор физически не работает. Этот метод лучше работает на маленьких наборах параметров. Но такие модели не сильно востребованы.
2) **Градиентные:** возможность в какую сторону изменять параметр (текущее изменение параметра), чтобы уменьшить функцию ошибки. На сегодня градиентные методы широко используются. Все основаны на вычисление производной. **Функции ошибки должны быть дифференцируемы.** Но реальные функции могут не иметь производных, тогда приходится создавать искусственно функцию ошибки.
   Есть значение функции ошибки, ищем ее производную функции ошибки, нужно измерять параметр так, чтобы уменьшить функцию ошибки. Судя по формуле **чтобы получить новое значение параметра нужно из старого значения вычесть производную функции ошибки умноженную на степень спуска.**   
   ![[Pasted image 20260121195327.png]]
   Проблемы: застревает в локальных минимумах - решение отчасти это перезапускать процесс, потому что результат может стать другим. Чувствителен к инициализации, к величине шага (learning rate (n / этта)), к шуму. Проблемы с узкими поверхностями, проблемы с широкими плато.
   ![[Pasted image 20260121204147.png]]
   Еще один гиперпараметр - количество циклов, чтобы добраться до минимума.
   **Знак градиента** - вместо значения градиента используется ее знак и шаг. Но есть минус, что можно попасть в петлю. Знак теряет направление производной. Вычисление знака намного проще для вычисления аппаратными средствами, чем значение. Но этот метод со знаком не востребован.
   **Плато** - если при вычислении производная ноль, мы продолжаем двигаться в том же направлении (прямолинейное движение). Во избежание ускорения, используется ГАММА для замедления (тормозится), чтобы он где-то остановился. (**ПЕРВЫЙ МОМЕНТ ИНЕРЦИИ**). Направление инерции может совпадать или не совпадать с направлением производной.
   ![[Pasted image 20260121210306.png]]
   ![[Pasted image 20260121210054.png]]
   **Усреднение. RMSProp** - градиентный спуск, который сам подстраивает размер шага для каждой ручки настройки, смотря на то, как сильно эта ручка раньше дергалась. [[RMSProp]]
   ![[Pasted image 20260121211657.png]]
   ![[Pasted image 20260121211252.png]]
   **Усреднение производной. AdaM** - метод по умолчанию. 
   **Изменение шага learning rate** - есть разные тенденции изменения этого гиперпараметра, каждый выбирает по своему. 
   **Методы второго порядка** - если мы точно знаем, что функция ошибки квадратичная. Но этот метод чувствителен к шумам. Вторая производная - матрица вторых производных и требует большой памяти. Используется для маленьких моделей.

По организации:
![[Pasted image 20260121193754.png]]
1) **Оффлайн**: считаем функцию ошибки на всем наборе данных и в конце меняем параметры один раз.
2) **Онлайн:** на каждом новом примере входных выходных данных считать функцию ошибки и оптимизировать параметры. Много раз изменять параметры модели. Недостаток: модель подстраивается под конкретный пример и не учитывает остальные.
3) **Пакетные:** данные разбивают на пакеты, и после подсчета функции ошибки на данном пакете меняются параметры модели до следующего пакета. Длина пакета - гиперпараметр.

По цикличности:
1) **Цикличные (итерационные):** постепенно изменяют параметры, для того чтобы уменьшать функции ошибки. У цикла есть начало. 
2) **Ацикличные:** за одно действие изменяют параметр (квадратичная функция ошибки).
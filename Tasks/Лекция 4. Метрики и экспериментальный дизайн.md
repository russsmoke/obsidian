	Функция ошибки - показывает насколько выходные параметры модели совпадают с ожидающим результатом.

Выбор функции ошибки зависит от того, какую задачу следует решить.
## Задачи
Есть крупные классы задач, к которым сводятся остальные задачи. Основная задача моделей - приближение некоторых функций зависимости входной информации к выходной. 
### Регрессия
![[Pasted image 20260210172514.png]]
Если выходная переменная, которую хотят смоделировать изменяется в непрерывном диапазоне, например, задача узнать температуру воздуха, если известна влажность, то такие задачи называют **задачами регрессии** (аппроксимации, приближения).
Подавляющее число задач являются задачами регрессии.

### Классификация
![[Pasted image 20260210172524.png]]
Частный случай регрессии, который накладывает ограничения на выходную переменную: выходная/целевая переменная представляет собой дискретное значение. Такого рода задача называется **задача классификации**.
Например, задача отличия котов от собак.
Некоторые задачи регрессии можно свести к задаче классификации, так как это является частным случаем. Но никак не наоборот.

### Прогнозирование
Решение задачи прогнозирования является решение задачи классификации или регрессии. 
*Является задачей регрессии:*
1) Прогнозирование спроса (сколько товаров купят в следующем месяце)
2) Прогнозирование цен
3) Прогнозирование времени (сколько времени продлится процесс)
4) Прогнозирование температуры, трафика и т.д.
Результат прогноза - конечное число, которое может принимать бесконечное количество значений в заданном диапазоне
*Является задачей классификации:*
- Предсказать дискретную метку/категорию
- Выходная переменная модели - класс (да/нет, спам/не спам)
### Ранжирование (LTR, Learning to Rank)
Цель - не предсказать точный класс или конкретное число, а упорядочить (ранжировать) объекты **относительно друг друга** в соответствии с их релевантностью или важностью 
1) Рекомендательные системы: ранжирование товаров, фильмов или музыки
2) Кредитный скоринг: ранжирование заявок по степени риска
## Кластеризация: близость значений
В задачах регрессии и классификации есть целевая выходная переменная. Но бывают ситуации когда этой целевой переменной нет. Если есть множество выходных переменных, то можно поставить задачу сравнения их между собой. 
Выяснить какие выходные переменные можно объединить в группы, а какие нет.
![[Pasted image 20260214125905.png]]
Суть - построение групп по метрикам близости. 
Эта задача не привязана к реальности, чтобы привязать, нужно провести классификацию. Принадлежат ли они к одной группе. 
***Современные модели искусственного интеллекта являются гибридными, в которых одновременно используются процессы обучения без учителя, и процесс дообучения с учителем.***
## Обучение с учителем - тест. Метрики и функции ошибки
Данные разбивают на обучающую выборку и на тестовую выборку. Чтобы оценить качество модели, используют метрики качества - математические инструменты.
### Метрики регрессии
Выход модели изменяется в непрерывном диапазоне и мы должны сравнить два числа. Как и функции ошибки как и метрики могут собираться на разных наборах данных (можно на обучающей, тестовой, части от датасета). Метрики для них будут разные, они оценивают качество модели с разных сторон.

Нужно различать бизнес (прикладные) метрики, которые можно измерять постфактум и те метрики, которые мы будем использовать чтобы СЕЙЧАС оценить качество работы модели (математические). 

Не факт, что хорошие математические метрики приведут к хорошим бизнес метрикам.
![[Pasted image 20260218140355.png]]

Все метрики - усредненные, по некоторому количеству примеров на которых рассчитываются. Важны не только абсолютные значения метрик, но их статистические свойства (разброс, насколько изменяются средние значения средних метрик). Следить как эти метрики изменялись по времени, улучшались. 

Тест мы делаем только тогда, когда модель уже полностью готова и обучена.
Помимо обучающей и тестовой выборки, есть проверочный - **validation**, который по своей сути является тестовым. Она похожа на тестовую тем, что на ней модель не обучается, но после нее принимается решение об изменении модели (добавление и изменение параметров, применять гиперпараметры). По тестовому набору мы не имеем права что то менять, только принимать решение об использовании модели в продакшене.

ПРОЧИТАТЬ ПРО МЕТРИКИ: https://habr.com/ru/articles/821547/
Метрика не одна. Метрик можно придумать бесконечное количество.
Математические метрики (для задач регрессии, для задач классификации). **Регрессия так устроена, что очень часто метрики совпадают с функцией ошибки. То есть метрики можно применять как функция ошибки.**
1) MSE (mean squared error - средняя квадратичная ошибка) = $1/n \sum_{i=1}^n(y_i-y^{~}_i)^2$ 
   Можно считать на одном примере или на пакете примеров. Квадрат расстояния. Большая чувствительность к большим ошибкам
2) MAE (mean absolute error - средняя абсолютная ошибка) =  $1/n \sum_{i=1}^n|y_i-y^{~}_i|$
3) MBE (mean bias error - средняя ошибка смещения) $1/n \sum_{i=1}^n(y_i-y^{~}_i)$
4) MAPE (mean absolute percentage error - средняя абсолютная процентная ошибка) = $1/n \sum_{i=1}^n|y_i-y^{~}_i|/y_i*100\%$ 
5) R^2 (коэффициент детерминации, R - квадрат, доля вариации зависимой переменной, объясняемую независимыми переменными в регрессионной модели. Насколько хорошо модель описывает изменения в наблюдаемых данных) = $1 - \sum_{i=1}^n(y^>_i-y_i)^2/\sum_{i=1}^n(y_i-y_i^-)^2$ 
6) Гибридные метрики ![[Pasted image 20260218145354.png]].
### Метрики классификации. Бинарная
Когда ответов всего два = положительный класс и отрицательный класс. В Бинарной классификации возможно 4 ситуации:
![[Pasted image 20260218145837.png]]
Самая главная метрика: какое количество правильных и неправильных предсказаний произошло. **Матрица ошибок (потерь, confusion matrix)** - показывает как много ошибок или распознаваний делает модель. (если классов больше чем 2, то матрица будет больше. сложно анализировать). В матрицу мы записываем именно долю или количество ответов.
Метрики:
1) Accuracy (аккуратность): ![[Pasted image 20260218150341.png]]
   Если классы несбалансированы, примеры разных классов разного количества, то метрика будет показывать судя по всем примерам, даже если один класс содержит примеров больше чем второй класс
2) Specificity (Специфичность): ![[Pasted image 20260218150526.png]]
3) Precision (Точность): ![[Pasted image 20260218150615.png]]
4) Recall (Транспонированность): ![[Pasted image 20260218150634.png]]
Recall и Precision объединяют в одну агрегированную метрику: $F\beta Score$
![[Pasted image 20260218150804.png]]
Если используют разные бета, то это разные метрики.
### Метрики классификации. AUC
Чтобы не приписывать к классам искажения и зависимости которых нет, есть способ кодирования. Когда многоклассовую классификацию превращают в набор бинарных классификаций.
Ответом нашей модели и целевой переменной будет вектор, длина которого совпадает с количеством классов. Состоящий из нулей и одной единички, место которого показывает конкретный класс.
![[Pasted image 20260218151309.png]]
One-hot кодирование - равноправные данные. (**унитарное кодирование**)

Модель возвращает столько выходов, сколько классов мы должны выделить в задаче. Модель возвращает вектор, который сравнивается с указанием учителя который представлен в виде унитарного вектора. Поэтому можем посчитать число совпадающий и несовпадающих классов. 

Мы можем рассматривать классификацию каждого класса как бинарную. Для определения одного класса, объединить остальные классы в один "неправильный". Составляем матрицу потерь.

Модели решают задачи регрессии, они возвращают значения из непрерывного диапазона. Появляется проблема: модель вернула 0.75, а должна была вернуть 1. Введем порог 0.5 и сравнить. Если выход больше, то класс 1, если меньше, то класс 0. Инженеры должны интерпретировать данные в числа. 

Матрица потерь и метрики будут зависеть и от порога. Надо рассматривать не одну модель, а семейство моделей с разным числом порога. Нужно сделать агрегированную метрику, которая агрегировала бы по порогу. Используется ROC - кривая ( receiver operating characteristic, рабочая характеристика приемника) - график, позволяющий оценить качество бинарной классификации. Представляет собой график для разных значений порога. 
![[Pasted image 20260218153628.png]]
https://habr.com/ru/companies/otus/articles/809147/

Введем метрику для сравнения модели с идеальной моделью (roc-curve). Считают площадь под кривой, чем ближе к 1, тем лучше. 

**Лайфхак (который работает только с бинарной классификацией)** - если метрика качества модели меньше 0.5, то у модели можно поменять названия классов и тогда можно сказать, что модель хорошо предугадывает значения.

Пример One-vs-Rest (OvR):
![[Pasted image 20260218152205.png]]
Для каждого класса можем посчитать метрики. 
Затем усредняем для всех данных: макроусреднение
![[Pasted image 20260218152254.png]]
Но нужно учитывать размеры классов. Поэтому берем средневзвешенное значение метрик:
![[Pasted image 20260218152450.png]]
Микро-усреднение. Сначала агрегируем значения в данных. Считаем сколько всего каких ответов:
![[Pasted image 20260218152635.png]]
НУЖНО СЧИТАТЬ ВСЕ И ПУБЛИКОВАТЬ.

Модель возвращает не класс, а некоторое число от 0 до 1. И мы принимаем решение какой класс в зависимости от порога. 
![[Pasted image 20260218155010.png]]
две модели выдали такой результат. Лучше будет та, что ближе к 1. Расстояние от выхода модели до целевой переменной это и есть уверенность модели в правильном распознавании или величина ошибки. 

Функция ошибки для задач классификации: logLoss
![[Pasted image 20260218155427.png]]
Уровень уверенности в модели
### Метрики Кластеризации
Сравниваем расстояния между примерами наших данных в входном пространстве и пытаемся выделить группы и собрать их в один кластер. Одной метрики для кластеризации нет, ее нельзя сделать. Это задача несамостоятельная, здесь нет правильных ответов. 

Но если задача кластеризации объединена с задачей классификации, то здесь можно выделить одну метрику. В ней есть эталонные кластеры (классы). Но это **редкость**.
Информация о конкретных кластерах потеряна. Сравнивать нужно пары данных, которые находятся в одном кластере неважно в каком. Считается количество ситуаций в которых пары расположены правильно. 
![[Pasted image 20260218160153.png]]
Кластер - распределение данных. Можно посчитать ширина кластера, расстояние между центрами кластеров (абсолютное и относительное) и принимать решение о качестве модели.

Если ширина кластера гораздо меньше, чем расстояние от центра другого кластера, то это хорошее распределение. Кластеры различимы
![[Pasted image 20260218161232.png]]
### Кроссвалидация
![[Pasted image 20260218161548.png]]
Все данные которые есть разобьем на несколько частей (блоков, foldы). Один фолд отложим для тестирования, а все остальные на обучения. Давайте сделаем другую модель и обучим ее на всех фолдах кроме одного. И таких моделей будет несколько. Каждая из которых обучалась честно и мы не использованы тестовые данные. И сделаем агрегированную общую модель, полученную из всех остальных моделей. Нечестно их объединили. 
Кроссвалидация нужна для тестирования. Если нет большого разброса в характеристиках метрик, значит модель хорошая. Если очень большой разброс, то модель обучена неправильно. От выбора поднабора данных для обучения зависят метрики.  